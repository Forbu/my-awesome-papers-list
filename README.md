## My personal papers list 

[Deep learning general](#Deep-learning-general)

[Reinforcement learning](#Reinforcement-learning)

[Generative model](#Generative-model)

[LLMs](#LLMs)

[GNNs](#GNNs)


### Deep learning general

- Loss of Plasticity in Deep Continual Learning : https://arxiv.org/abs/2306.13812
  
Discussion about the issue of loss of ability to learn in NN
New algorithm to improve continual learning 

- [Git Re-Basin: Merging Models modulo Permutation Symmetries](https://arxiv.org/abs/2209.04836)
Interesting theorical approach that said that there is a lot of useless symetries in NN

- [End-to-end Algorithm Synthesis with Recurrent Networks: Logical...](https://arxiv.org/abs/2202.05826)
Using recurrent modeliing to do OOD generalization

- https://journals.aps.org/prresearch/pdf/10.1103/PhysRevResearch.5.043252
Interesting take on forecasting chaotic time series

### Reinforcement learning 

- Sample-efficient reinforcement learningby breaking the replay ratio barrier [https://openreview.net/pdf?id=4GBGwVIEYJ](https://openreview.net/pdf?id=4GBGwVIEYJ "https://openreview.net/pdf?id=4GBGwVIEYJ")

-  Mastering Diverse Domains through World Models : dreamerv3 https://arxiv.org/pdf/2301.04104.pdf
Interesting Symlog Predictions for reward scaling

- [Bigger, Better, Faster: Human-level Atari with human-level efficiency](https://arxiv.org/abs/2305.19452)
Extensive use of shrink and reset (continual learning)

- Decision diffuser (inverse RL with diffusion) :
https://arxiv.org/pdf/2211.15657.pdf
Take into acount the stochastic RL env

- DO TRANSFORMER WORLD MODELS GIVE BETTER POLICY GRADIENTS?
https://arxiv.org/pdf/2402.05290.pdf
Good world model approach

### Generative model 

- MeshGPT : https://nihalsid.github.io/mesh-gpt/static/MeshGPT.pdf#page=9&zoom=100,412,724

**Machting flow papers** :

- https://arxiv.org/pdf/2210.02747.pdf
Simply explain matching flow for continuous variable
  
- https://arxiv.org/pdf/2302.00482.pdf matching flow with OT optim
  
- https://arxiv.org/pdf/2403.03206.pdf SB3 with matching flow

- https://arxiv.org/pdf/2404.19739v1 MF with categorical variable

**Graph Generation**

- https://arxiv.org/pdf/2312.11529.pdf
Graph generation : multi level graph generation thanks to Coarsening



### LLMs 

- Reinforced Self-Training (ReST) for Language Modeling : https://arxiv.org/pdf/2308.08998.pdf
Methodo to improve LLM if you have a reward function at your disposal

- [Direct Preference Optimization: Your Language Model is Secretly a R...](https://arxiv.org/abs/2305.18290)
A good preference optimization scheme (if you have a preference dataset)

- [Constitutional AI: Harmlessness from AI Feedback](https://arxiv.org/abs/2212.08073)

- Direct Nash Optimization: Teaching Language Models to Self-Improve with General Preferences :
		https://arxiv.org/abs/2404.03715

- https://arxiv.org/pdf/2309.07864.pdf#page=67&zoom=100,144,670
  toolformer

- https://arxiv.org/pdf/2306.00637.pdf
Stable cascade : a efficient way to train image generation with NLP instruct

### GNNs 

- https://proceedings.mlr.press/v202/shirzad23a/shirzad23a.pdf (EXPHORMER: Sparse Transformers for Graphs)

### Symetry group in DL

- https://arxiv.org/pdf/2203.06153
Symmetry Group Equivariant Architectures for Physics

- https://arxiv.org/pdf/1802.08219
  Equivariant learning (just use sperical harmonics)

### Other

- https://proceedings.mlr.press/v206/bertrand23a/bertrand23a.pdf
Other thing than elo to rank player

