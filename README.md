## My personal papers list 

[Deep learning general](#Deep-learning-general)

[Reinforcement learning](#Reinforcement-learning)

[Generative model](#Generative-model)

[LLMs](#LLMs)

[GNNs](#GNNs)


### Deep learning general {#Deep-learning-general}

- Loss of Plasticity in Deep Continual Learning : https://arxiv.org/abs/2306.13812
  
Discussion about the issue of loss of ability to learn in NN
New algorithm to improve continual learning 

- [Git Re-Basin: Merging Models modulo Permutation Symmetries](https://arxiv.org/abs/2209.04836)
Interesting theorical approach that said that there is a lot of useless symetries in NN

- [End-to-end Algorithm Synthesis with Recurrent Networks: Logical...](https://arxiv.org/abs/2202.05826)
Using recurrent modeliing to do OOD generalization

### Reinforcement learning {#Reinforcement-learning}

- Sample-efficient reinforcement learningby breaking the replay ratio barrier [https://openreview.net/pdf?id=4GBGwVIEYJ](https://openreview.net/pdf?id=4GBGwVIEYJ "https://openreview.net/pdf?id=4GBGwVIEYJ")

-  Mastering Diverse Domains through World Models : dreamerv3 https://arxiv.org/pdf/2301.04104.pdf
Interesting Symlog Predictions for reward scaling

- [Bigger, Better, Faster: Human-level Atari with human-level efficiency](https://arxiv.org/abs/2305.19452)
Extensive use of shrink and reset (continual learning)


### Generative model {#Generative-model}

**Machting flow papers** :

- https://arxiv.org/pdf/2210.02747.pdf
Simply explain matching flow for continuous variable
  
- https://arxiv.org/pdf/2302.00482.pdf matching flow with OT optim
  
- https://arxiv.org/pdf/2403.03206.pdf SB3 with matching flow

- https://arxiv.org/pdf/2404.19739v1 MF with categorical variable

### LLMs {#LLMs}

- Reinforced Self-Training (ReST) for Language Modeling : https://arxiv.org/pdf/2308.08998.pdf
Methodo to improve LLM if you have a reward function at your disposal

- [Direct Preference Optimization: Your Language Model is Secretly a R...](https://arxiv.org/abs/2305.18290)
A good preference optimization scheme (if you have a preference dataset)

- [Constitutional AI: Harmlessness from AI Feedback](https://arxiv.org/abs/2212.08073)

- Direct Nash Optimization: Teaching Language Models to Self-Improve with General Preferences :
		https://arxiv.org/abs/2404.03715

### GNNs {#GNNs}


- https://proceedings.mlr.press/v202/shirzad23a/shirzad23a.pdf (EXPHORMER: Sparse Transformers for Graphs)
